{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9ybrAdoVaEv6mWTMNqhBU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advik-7/Image_Encryption/blob/main/Discriminator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "def build_discriminator():\n",
        "    image_input = layers.Input(shape=(256, 256, 3))  # Input shape\n",
        "\n",
        "    x = layers.Conv2D(64, kernel_size=4, strides=2, padding='same')(image_input)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(512, kernel_size=4, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    validity = layers.Dense(1, activation='sigmoid')(x)\n",
        "    discriminator_model = Model(image_input, validity)\n",
        "\n",
        "    def discriminator_loss(real, fake):\n",
        "        real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(real), real)\n",
        "        fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake), fake)\n",
        "        return (real_loss + fake_loss) * 0.5\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "    def train_step(real_images, fake_images):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Get the validity of real and fake images\n",
        "            real_validity = discriminator_model(real_images, training=True)\n",
        "            fake_validity = discriminator_model(fake_images, training=True)\n",
        "\n",
        "            # = loss\n",
        "            loss = discriminator_loss(real_validity, fake_validity)\n",
        "\n",
        "        #Optimixer\n",
        "        gradients = tape.gradient(loss, discriminator_model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, discriminator_model.trainable_variables))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    return discriminator_model, train_step\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3eG1E3c9_DQJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}